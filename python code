#!/usr/bin/env python
import os, sys
import glob
import re
import nltk
from nltk.tokenize import RegexpTokenizer
from nltk.util import ngrams
from nltk.stem.wordnet import WordNetLemmatizer

# for create unigram, I used lemmatization
path = "/home/admin1/Documents/Machine_learning/txt_sentoken/neg/*.txt"
#also change path to 'pos' file 
#out_path="/home/admin1/Documents/Machine_learning/txt_sentoken/lemma/pos/"
files = glob.glob(path)   
for name in files:
	f=open(name,'r')
	myfile=f.read()
	myfile_remove_num=re.sub(r'\d+','',myfile)
	tokenizer= RegexpTokenizer(r'\w+')
	st = WordNetLemmatizer()
	tokens = tokenizer.tokenize(myfile_remove_num)
	output = []
	for token in tokens :
		lemma = st.lemmatize(token,'v')
		output += [lemma]		
	out=open(name,'w',encoding='UTF-8')
	out.write(str(output)+'\n')
	out.close()
 
 # for create bigram 
 path = "/home/admin1/Documents/Machine_learning/txt_sentoken/lemma/bigram/neg/*.txt"
files = glob.glob(path) 
for name in files:
	f=open(name,'r').read()
	myfile_remove_num=re.sub(r'\d+','',f)
	myfile_remove_bracket=re.sub('[(){}<>]', '', myfile_remove_num)
	tokens= myfile_remove_bracket.split()
	st = WordNetLemmatizer()
	output = []
	for token in tokens :
		lemma = st.lemmatize(token,'v')	
		output += [lemma]
	mlbigram =list(nltk.bigrams(output))				
	with open(name, 'w') as file_handler:
    		for item in mlbigram:
        		file_handler.write("{}\n".format(item))
        		
  # for create vocab
# step one 
path = "/home/admin1/Documents/Machine_learning/txt_sentoken/lemma/bigram/pos/*.txt"
# also use 'pos' file
files = glob.glob(path) 
with open('/home/admin1/Documents/Machine_learning/txt_sentoken/lemma/bigram/vocab.txt', 'w') as outfile:
    for name in files:
        with open(name) as infile:
            for line in infile:
                outfile.write(line)
path = "/home/admin1/Documents/Machine_learning/txt_sentoken/lemma/bigram/neg/*.txt"
files = glob.glob(path) 
with open('/home/admin1/Documents/Machine_learning/txt_sentoken/lemma/bigram/vocab.txt', 'a') as outfile:
    for name in files:
        with open(name) as infile:
            for line in infile:
                outfile.write(line)
#step two 


 
